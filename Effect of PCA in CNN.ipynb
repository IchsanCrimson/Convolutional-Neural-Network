{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2301888682 - ICHSAN - CASE\n",
    "## A.\n",
    "### Step 1: Read DNA and Fashion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   SAMPLE_ID  snp_0  snp_1  snp_2  snp_3  snp_4  snp_5  snp_6  snp_7  snp_8  \\\n",
       " 0     HCB181      1      0      0      1      1      2      2      2      2   \n",
       " 1     HCB182      1      0      0      1      1      2      2      1      2   \n",
       " 2     HCB183      1      0      0      1      2      2      2      1      2   \n",
       " 3     HCB184      1      0      0      1      1      2      2      1      2   \n",
       " 4     HCB185      1      0      0      1      1      2      2      1      2   \n",
       " ..       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       " 84    JPT265      1      0      0      1      1      1      1      2      2   \n",
       " 85    JPT266      1      0      0      1      2      2      2      1      2   \n",
       " 86    JPT267      1      0      0      1      2      1      2      2      2   \n",
       " 87    JPT268      1      0      0      1      2      2      2      2      2   \n",
       " 88    JPT269      1      0      0      1      2      2      2      2      2   \n",
       " \n",
       "     ...  snp_9992  snp_9993  snp_9994  snp_9995  snp_9996  snp_9997  snp_9998  \\\n",
       " 0   ...         2         2         2         1         2         1         2   \n",
       " 1   ...         1         1         2         2         2         1         2   \n",
       " 2   ...         2         2         2         1         2         2         2   \n",
       " 3   ...         2         2         2         1         2         2         2   \n",
       " 4   ...         2         2         2         2         2         2         2   \n",
       " ..  ...       ...       ...       ...       ...       ...       ...       ...   \n",
       " 84  ...         2         2         2         1         1         2         2   \n",
       " 85  ...         2         2         2         1         2         2         2   \n",
       " 86  ...         2         2         2         2         2         1         1   \n",
       " 87  ...         2         2         2         1         2         1         2   \n",
       " 88  ...         2         2         2         2         2         1         2   \n",
       " \n",
       "     snp_9999  snp_10000  STATUS  \n",
       " 0          1          2       1  \n",
       " 1          2          2       2  \n",
       " 2          1          2       2  \n",
       " 3          1          2       2  \n",
       " 4          2          2       1  \n",
       " ..       ...        ...     ...  \n",
       " 84         1          1       2  \n",
       " 85         1          2       2  \n",
       " 86         2          2       1  \n",
       " 87         1          1       1  \n",
       " 88         2          2       2  \n",
       " \n",
       " [89 rows x 10003 columns],\n",
       " ((array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          ...,\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "   array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)),\n",
       "  (array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          ...,\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]],\n",
       "   \n",
       "          [[0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           ...,\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0],\n",
       "           [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "   array([9, 2, 1, ..., 8, 1, 5], dtype=uint8))))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "data_dna = pd.read_csv(\"rawdata.csv\")\n",
    "data_fashion = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = data_fashion\n",
    "\n",
    "data_dna, data_fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Determine x and y values of DNA and Fashion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 10001), (89, 1), (70000, 28, 28), (70000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_dna = data_dna.drop(columns = [\"SAMPLE_ID\", \"STATUS\"])\n",
    "y_dna = data_dna[[\"STATUS\"]]\n",
    "\n",
    "x_fashion = np.append(x_train_fashion, x_test_fashion, axis = 0)\n",
    "y_fashion = np.append(y_train_fashion, y_test_fashion, axis = 0)\n",
    "\n",
    "x_dna.shape, y_dna.shape, x_fashion.shape, y_fashion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Normalize x and y values of DNA and Fashion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data DNA:\n",
      "x: 0.0 1.0\n",
      "Data Fashion:\n",
      "x: 0.0 1.0\n",
      "\n",
      "Data DNA:     (89, 10001) (89, 2)\n",
      "Data Fashion: (70000, 28, 28) (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "def normalize(scaler, data):\n",
    "    scaler.fit(data)\n",
    "    return scaler, scaler.transform(data)\n",
    "\n",
    "\n",
    "scaler_x_dna, x_dna_norm = normalize(MinMaxScaler(), x_dna)\n",
    "scaler_y_dna, y_dna_norm = normalize(OneHotEncoder(sparse = False), y_dna)\n",
    "\n",
    "x_fashion_norm = x_fashion / 255.0\n",
    "scaler_y_fashion, y_fashion_norm = normalize(OneHotEncoder(sparse = False), y_fashion.reshape(-1, 1))\n",
    "\n",
    "\n",
    "print(\"Data DNA:\")\n",
    "print(\"x:\", x_dna_norm.min(), x_dna_norm.max())\n",
    "print(\"Data Fashion:\")\n",
    "print(\"x:\", x_fashion_norm.min(), x_fashion_norm.max())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Data DNA:    \", x_dna_norm.shape, y_dna_norm.shape)\n",
    "print(\"Data Fashion:\", x_fashion_norm.shape, y_fashion_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Find PCA of DNA and Fashion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data DNA:     (89, 82, 1) (89, 10001, 1) (89, 2)\n",
      "Data Fashion: (70000, 188, 1) (70000, 28, 28, 1) (70000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca(model, data):\n",
    "    model.fit(data)\n",
    "    return model, model.transform(data)\n",
    "\n",
    "\n",
    "pca_dna, x_dna_pca = pca(PCA(n_components = 0.95), x_dna_norm)\n",
    "pca_fashion, x_fashion_pca = pca(PCA(n_components = 0.95), x_fashion_norm.reshape(-1, 28*28))\n",
    "\n",
    "x_dna_pca = x_dna_pca.reshape(len(x_dna_pca), -1, 1)\n",
    "x_dna_norm = x_dna_norm.reshape(len(x_dna_norm), -1, 1)\n",
    "x_fashion_pca = x_fashion_pca.reshape(len(x_fashion_pca), -1, 1)\n",
    "x_fashion_norm = x_fashion_norm.reshape(len(x_fashion_norm), 28, 28, 1)\n",
    "\n",
    "\n",
    "print(\"Data DNA:    \", x_dna_pca.shape, x_dna_norm.shape, y_dna_norm.shape)\n",
    "print(\"Data Fashion:\", x_fashion_pca.shape, x_fashion_norm.shape, y_fashion_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Split Training, Validation, and Testing set\n",
    "#### DNA data: Train 80%, Validation 10%, Test 10%\n",
    "#### Fashion data: Train 60000, Validation 5000, Test 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data DNA:\n",
      "\tx     (71, 10001, 1) (9, 10001, 1) (9, 10001, 1)\n",
      "\tx_pca (71, 82, 1) (9, 82, 1) (9, 82, 1)\n",
      "\ty     (71, 2) (9, 2) (9, 2)\n",
      "\n",
      "Data Fashion:\n",
      "\tx     (60000, 28, 28, 1) (5000, 28, 28, 1) (5000, 28, 28, 1)\n",
      "\tx_pca (60000, 188, 1) (5000, 188, 1) (5000, 188, 1)\n",
      "\ty     (60000, 10) (5000, 10) (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "def train_val_test_split(split, data):\n",
    "    data_train = data[:split]\n",
    "    sisa = data[split:]\n",
    "    \n",
    "    split = int(0.5*len(sisa))\n",
    "    data_val = sisa[:split]\n",
    "    data_test = sisa[split:]\n",
    "    \n",
    "    return data_train, data_val, data_test\n",
    "\n",
    "\n",
    "train_size_dna = int(0.8*len(x_dna))\n",
    "x_train_dna_pca, x_val_dna_pca, x_test_dna_pca = train_val_test_split(train_size_dna, x_dna_pca)\n",
    "x_train_dna, x_val_dna, x_test_dna = train_val_test_split(train_size_dna, x_dna_norm)\n",
    "y_train_dna, y_val_dna, y_test_dna = train_val_test_split(train_size_dna, y_dna_norm)\n",
    "\n",
    "\n",
    "train_size_fashion = 60000\n",
    "x_train_fashion_pca, x_val_fashion_pca, x_test_fashion_pca = train_val_test_split(train_size_fashion, x_fashion_pca)\n",
    "x_train_fashion, x_val_fashion, x_test_fashion = train_val_test_split(train_size_fashion, x_fashion_norm)\n",
    "y_train_fashion, y_val_fashion, y_test_fashion = train_val_test_split(train_size_fashion, y_fashion_norm)\n",
    "\n",
    "\n",
    "print(\"Data DNA:\")\n",
    "print(\"\\tx    \", x_train_dna.shape, x_val_dna.shape, x_test_dna.shape)\n",
    "print(\"\\tx_pca\", x_train_dna_pca.shape, x_val_dna_pca.shape, x_test_dna_pca.shape)\n",
    "print(\"\\ty    \", y_train_dna.shape, y_val_dna.shape, y_test_dna.shape)\n",
    "print()\n",
    "print(\"Data Fashion:\")\n",
    "print(\"\\tx    \", x_train_fashion.shape, x_val_fashion.shape, x_test_fashion.shape)\n",
    "print(\"\\tx_pca\", x_train_fashion_pca.shape, x_val_fashion_pca.shape, x_test_fashion_pca.shape)\n",
    "print(\"\\ty    \", y_train_fashion.shape, y_val_fashion.shape, y_test_fashion.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Initialize DataFrame to Summarize Accuracy Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNA dataset</th>\n",
       "      <th>Fashion MNIST dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA + CNN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DNA dataset Fashion MNIST dataset\n",
       "PCA + CNN         NaN                   NaN\n",
       "CNN               NaN                   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(index = [\"PCA + CNN\", \"CNN\"], columns = [\"DNA dataset\", \"Fashion MNIST dataset\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Build Model, Train Model, Test Model, and Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 755ms/step - loss: 0.7140 - accuracy: 0.4957 - val_loss: 0.6868 - val_accuracy: 0.5556\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 0.7080 - accuracy: 0.5067 - val_loss: 0.7181 - val_accuracy: 0.4444\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 0.6983 - accuracy: 0.4996 - val_loss: 0.7295 - val_accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 403ms/step - loss: 0.6962 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5556\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 359ms/step - loss: 0.6876 - accuracy: 0.6348 - val_loss: 0.6888 - val_accuracy: 0.5556\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 380ms/step - loss: 0.6880 - accuracy: 0.5379 - val_loss: 0.7214 - val_accuracy: 0.4444\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.6914 - accuracy: 0.5113 - val_loss: 0.6873 - val_accuracy: 0.5556\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 399ms/step - loss: 0.6859 - accuracy: 0.5403 - val_loss: 0.6977 - val_accuracy: 0.4444\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 372ms/step - loss: 0.6830 - accuracy: 0.5113 - val_loss: 0.6870 - val_accuracy: 0.5556\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 0.6819 - accuracy: 0.5160 - val_loss: 0.7117 - val_accuracy: 0.4444\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6662 - accuracy: 0.6667\n",
      "DNA dataset - (CNN) = 66.66666865348816%\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 341ms/step - loss: 1.1251 - accuracy: 0.4879 - val_loss: 1.1687 - val_accuracy: 0.4444\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0024 - accuracy: 0.5113 - val_loss: 1.0523 - val_accuracy: 0.4444\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.9380 - accuracy: 0.4879 - val_loss: 0.9514 - val_accuracy: 0.4444\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.8684 - accuracy: 0.4840 - val_loss: 0.8835 - val_accuracy: 0.4444\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7747 - accuracy: 0.5231 - val_loss: 0.8091 - val_accuracy: 0.4444\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7642 - accuracy: 0.4840 - val_loss: 0.7814 - val_accuracy: 0.4444\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7272 - accuracy: 0.5035 - val_loss: 0.7545 - val_accuracy: 0.4444\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7026 - accuracy: 0.5152 - val_loss: 0.7463 - val_accuracy: 0.4444\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6889 - accuracy: 0.5426 - val_loss: 0.7204 - val_accuracy: 0.4444\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6964 - accuracy: 0.4879 - val_loss: 0.7172 - val_accuracy: 0.5556\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7178 - accuracy: 0.6667\n",
      "DNA dataset - (PCA + CNN) = 66.66666865348816%\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 134s 71ms/step - loss: 1.6194 - accuracy: 0.4679 - val_loss: 0.9761 - val_accuracy: 0.6828\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 134s 71ms/step - loss: 0.8674 - accuracy: 0.7178 - val_loss: 0.7141 - val_accuracy: 0.7608\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 132s 71ms/step - loss: 0.6711 - accuracy: 0.7724 - val_loss: 0.6256 - val_accuracy: 0.7868\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 133s 71ms/step - loss: 0.5898 - accuracy: 0.7922 - val_loss: 0.5790 - val_accuracy: 0.7934\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 134s 72ms/step - loss: 0.5363 - accuracy: 0.8095 - val_loss: 0.5503 - val_accuracy: 0.8016\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.5015 - accuracy: 0.8223 - val_loss: 0.5136 - val_accuracy: 0.8210\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 130s 69ms/step - loss: 0.4650 - accuracy: 0.8361 - val_loss: 0.4791 - val_accuracy: 0.8418\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 134s 71ms/step - loss: 0.4378 - accuracy: 0.8496 - val_loss: 0.4527 - val_accuracy: 0.8468\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.4161 - accuracy: 0.8592 - val_loss: 0.4171 - val_accuracy: 0.8626\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 136s 72ms/step - loss: 0.3859 - accuracy: 0.8690 - val_loss: 0.4009 - val_accuracy: 0.8682\n",
      "157/157 [==============================] - 3s 16ms/step - loss: 0.4005 - accuracy: 0.8612\n",
      "Fashion MNIST dataset - (CNN) = 86.11999750137329%\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 38s 19ms/step - loss: 2.2802 - accuracy: 0.1637 - val_loss: 1.8110 - val_accuracy: 0.4106\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 1.6091 - accuracy: 0.4924 - val_loss: 1.1431 - val_accuracy: 0.6534\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 1.0407 - accuracy: 0.6880 - val_loss: 0.8495 - val_accuracy: 0.7464\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.7867 - accuracy: 0.7671 - val_loss: 0.7045 - val_accuracy: 0.7812\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.6578 - accuracy: 0.8012 - val_loss: 0.6186 - val_accuracy: 0.8038\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.5782 - accuracy: 0.8210 - val_loss: 0.5672 - val_accuracy: 0.8184\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.5332 - accuracy: 0.8294 - val_loss: 0.5407 - val_accuracy: 0.8236\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.4996 - accuracy: 0.8397 - val_loss: 0.5185 - val_accuracy: 0.8278\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.4808 - accuracy: 0.8436 - val_loss: 0.4964 - val_accuracy: 0.8324\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.4563 - accuracy: 0.8510 - val_loss: 0.4809 - val_accuracy: 0.8358\n",
      "157/157 [==============================] - 1s 9ms/step - loss: 0.4820 - accuracy: 0.8392\n",
      "Fashion MNIST dataset - (PCA + CNN) = 83.92000198364258%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Conv2D, Flatten, Dense, MaxPooling1D, MaxPooling2D\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "def build_model(dimensi, output_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(dimensi == 1):\n",
    "        model.add(Conv1D(32, 3, activation = \"relu\"))\n",
    "        model.add(Conv1D(16, 3, activation = \"relu\"))\n",
    "        model.add(MaxPooling1D(pool_size = 3, strides = 1, padding = \"valid\"))\n",
    "        model.add(Conv1D(8, 3, activation = \"relu\"))\n",
    "        model.add(MaxPooling1D(pool_size = 2, strides = 1, padding = \"valid\"))\n",
    "    elif(dimensi == 2):\n",
    "        model.add(Conv2D(32, (3, 3), activation = \"relu\"))\n",
    "        model.add(Conv2D(16, (3, 3), activation = \"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (3, 3), strides = (1, 1), padding='valid'))\n",
    "        model.add(Conv2D(8, (3, 3), activation = \"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1), padding='valid'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation = \"sigmoid\"))\n",
    "    model.add(Dense(output_shape, activation = \"softmax\"))\n",
    "    model.compile(optimizer = \"SGD\", loss = \"CategoricalCrossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "class_dna = len(y_train_dna[0])\n",
    "\n",
    "CNN_dna = build_model(1, class_dna)\n",
    "CNN_dna.fit(x_train_dna, y_train_dna, validation_data = (x_val_dna, y_val_dna), epochs = 10)\n",
    "_, accuracy = CNN_dna.evaluate(x_test_dna, y_test_dna)\n",
    "result[\"DNA dataset\"][\"CNN\"] = str(accuracy*100) + \"%\"\n",
    "print(\"DNA dataset - (CNN) =\", result[\"DNA dataset\"][\"CNN\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "PCA_CNN_dna = build_model(1, class_dna)\n",
    "PCA_CNN_dna.fit(x_train_dna_pca, y_train_dna, validation_data = (x_val_dna_pca, y_val_dna), epochs = 10)\n",
    "_, accuracy = PCA_CNN_dna.evaluate(x_test_dna_pca, y_test_dna)\n",
    "result[\"DNA dataset\"][\"PCA + CNN\"] = str(accuracy*100) + \"%\"\n",
    "print(\"DNA dataset - (PCA + CNN) =\", result[\"DNA dataset\"][\"PCA + CNN\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "class_fashion = len(y_train_fashion[0])\n",
    "\n",
    "CNN_fashion = build_model(2, class_fashion)\n",
    "CNN_fashion.fit(x_train_fashion, y_train_fashion, validation_data = (x_val_fashion, y_val_fashion), epochs = 10)\n",
    "_, accuracy = CNN_fashion.evaluate(x_test_fashion, y_test_fashion)\n",
    "result[\"Fashion MNIST dataset\"][\"CNN\"] = str(accuracy*100) + \"%\"\n",
    "print(\"Fashion MNIST dataset - (CNN) =\", result[\"Fashion MNIST dataset\"][\"CNN\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "PCA_CNN_fashion = build_model(1, class_fashion)\n",
    "PCA_CNN_fashion.fit(x_train_fashion_pca, y_train_fashion, validation_data = (x_val_fashion_pca, y_val_fashion), epochs = 10)\n",
    "_, accuracy = PCA_CNN_fashion.evaluate(x_test_fashion_pca, y_test_fashion)\n",
    "result[\"Fashion MNIST dataset\"][\"PCA + CNN\"] = str(accuracy*100) + \"%\"\n",
    "print(\"Fashion MNIST dataset - (PCA + CNN) =\", result[\"Fashion MNIST dataset\"][\"PCA + CNN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Show Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNA dataset</th>\n",
       "      <th>Fashion MNIST dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA + CNN</th>\n",
       "      <td>66.66666865348816%</td>\n",
       "      <td>83.92000198364258%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>66.66666865348816%</td>\n",
       "      <td>86.11999750137329%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  DNA dataset Fashion MNIST dataset\n",
       "PCA + CNN  66.66666865348816%    83.92000198364258%\n",
       "CNN        66.66666865348816%    86.11999750137329%"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
